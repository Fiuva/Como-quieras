{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89668beb",
   "metadata": {},
   "source": [
    "# Dog vs Cat\n",
    "\n",
    "## Extracción de características 2\n",
    "\n",
    "Importamos algunas librerías que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42155d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d59116",
   "metadata": {},
   "source": [
    "Instalamos tensorflow si no lo tenemos instalado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f288a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c012e9d",
   "metadata": {},
   "source": [
    "Inicializamos variables\n",
    "\n",
    "En este caso utilizaremos el dataset `cat_dog_100` pero en cualquier momento se puede cambiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e7e4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rutaDogsTrain = 'cat_dog_100/train/dog'\n",
    "rutaDogsTest = 'cat_dog_100/test/dog'\n",
    "rutaCatsTrain = 'cat_dog_100/train/cat'\n",
    "rutaCatsTest = 'cat_dog_100/test/cat'\n",
    "\n",
    "tamanoMax = 256\n",
    "sizeVentana = 16\n",
    "tamanoMax = int(tamanoMax/sizeVentana)*sizeVentana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3950c2d0",
   "metadata": {},
   "source": [
    "Se recorren los directorios para obtener los nombres de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1648a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_dog_100/train/dog/dog.10000.jpg\n"
     ]
    }
   ],
   "source": [
    "from os import walk\n",
    "\n",
    "dogTrain = []\n",
    "dogTest = []\n",
    "catTest = []\n",
    "catTrain = []\n",
    "for (dirpath, dirnames, filenames) in walk(rutaDogsTrain):\n",
    "    dogTrain.extend(filenames)\n",
    "    \n",
    "for (dirpath, dirnames, filenames) in walk(rutaDogsTest):\n",
    "    dogTest.extend(filenames)\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(rutaCatsTest):\n",
    "    catTest.extend(filenames)\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(rutaCatsTrain):\n",
    "    catTrain.extend(filenames)\n",
    "    \n",
    "print(f'{rutaDogsTrain}/{dogTrain[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58712a53",
   "metadata": {},
   "source": [
    "La función `resize_image` redimensiona la imagen en *tamanoMax x tamanoMax*.\n",
    "\n",
    "Probaremos a recortar la imagen para no deformarlas y así comprobar si obtenemos un mejor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79b29067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recorta_imagen(imagen, n):\n",
    "    \"\"\"\n",
    "    Esta función recibe una imagen y un tamaño n y recorta la imagen de tal manera que el número final de filas/columnas \n",
    "    sea múltiplo de n. La funció debe recortar las filas de la derecha/abajo.\n",
    "    \"\"\"\n",
    "    size = np.min([int(imagen.shape[0]/n)*n, int(imagen.shape[1]/n)*n])\n",
    "    return imagen[:size, :size]\n",
    "\n",
    "def resize_image(imagen, sizeVentana, tamanoMax, recorta=False):\n",
    "    if(recorta): imagen = recorta_imagen(imagen, sizeVentana)\n",
    "    imagen2 = cv2.resize(imagen, [tamanoMax,tamanoMax])\n",
    "    return imagen2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a87dd8",
   "metadata": {},
   "source": [
    "Función para aplicar un filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79703d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro(imagen, mascara):\n",
    "    a = mascara.shape[0]//2\n",
    "    b = mascara.shape[1]//2\n",
    "    imagen_ampliada = cv2.copyMakeBorder(imagen, a, a, b, b, cv2.BORDER_REPLICATE)\n",
    "    imagen2 = np.zeros(imagen.shape)\n",
    "    for i in range(a, imagen.shape[0] + a):\n",
    "        for j in range(b, imagen.shape[1] + b):\n",
    "            imagen2[i-a, j-b] = np.sum(imagen_ampliada[i-a:i+a+1, j-b:j+b+1] * mascara)\n",
    "            \n",
    "    return imagen2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece1661",
   "metadata": {},
   "source": [
    "Función para aplicar un filtro espacial de aproximación de la derivada parcial y obtenemos Phi y E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cc49f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente(imagen):\n",
    "    m_g_x = np.array([[0, -1, 0], [0, 0, 0], [0, 1, 0]])\n",
    "    m_g_y = np.array([[0, 0, 0], [-1, 0, 1], [0, 0, 0]])\n",
    "    Ix = filtro(imagen, m_g_x)\n",
    "    Iy = filtro(imagen, m_g_y)\n",
    "    E = np.sqrt(Ix**2 + Iy**2)\n",
    "    Phi = np.rad2deg(np.arctan2(Iy, Ix))\n",
    "    \n",
    "    return E, Phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732adfcb",
   "metadata": {},
   "source": [
    "La función `transforma_imagen` divide en celdas de tamaños sizeVentana y contruimos un histograma para cada celda en función de Phi y E "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36b00274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_bloque(celdaPhi, celdaE, bins = 9):\n",
    "    celdaPhi = np.abs(celdaPhi)\n",
    "    hp = cv2.calcHist([np.uint8(celdaPhi)], [0], None, [bins], [0, 180])\n",
    "    a = 180/bins \n",
    "    for i in range(bins):\n",
    "        hp[i] += np.sum(celdaE[(celdaPhi > a*i) & (celdaPhi < -a*(i+1))])\n",
    "    hp = hp / np.sqrt(np.sum(hp**2)) #Normalizar\n",
    "    return np.ravel(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acb14469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_imagen(imagen, sizeVentana, tamanoMax):\n",
    "    E, Phi = gradiente(imagen)\n",
    "    Phi = resize_image(Phi, sizeVentana, tamanoMax, False)  #Mejor recortar a True\n",
    "    E = resize_image(E, sizeVentana, tamanoMax, False) #Mejor recortar a True\n",
    "    caracteristicas = []\n",
    "    a = int(Phi.shape[0]/sizeVentana)\n",
    "    for i in range(a):\n",
    "        for j in range(a):\n",
    "            celdaPhi = Phi[i*sizeVentana:(i+1)*sizeVentana,j*sizeVentana:(j+1)*sizeVentana]\n",
    "            celdaE = E[i*sizeVentana:(i+1)*sizeVentana,j*sizeVentana:(j+1)*sizeVentana]\n",
    "            h = transforma_bloque(celdaPhi, celdaE)  \n",
    "            caracteristicas.append(h)\n",
    "    return np.concatenate(caracteristicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2686e",
   "metadata": {},
   "source": [
    "Extraemos las características de nuestro conjunto de imágenes (Train y Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44cc5cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perros: 100%|\u001b[38;2;255;136;248m████████████████████████████████████████████████████████████████████████\u001b[0m| 100/100 [05:44<00:00,  3.44s/it]\u001b[0m\n",
      "Gatos: 100%|\u001b[38;2;136;255;221m█████████████████████████████████████████████████████████████████████████\u001b[0m| 100/100 [05:34<00:00,  3.34s/it]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "m = 2\n",
    "for i in tqdm(range(len(dogTrain)), desc = \"Perros\", colour = '#FF88F8'):\n",
    "    imagen = cv2.imread(f'{rutaDogsTrain}/{dogTrain[i]}',0)\n",
    "    caracteristicas = transforma_imagen(imagen, sizeVentana, tamanoMax)\n",
    "    X.append(caracteristicas)\n",
    "\n",
    "for i in tqdm(range(len(catTrain)), desc = \"Gatos\", colour = '#88FFDD'):\n",
    "    imagen = cv2.imread(f'{rutaCatsTrain}/{catTrain[i]}',0)\n",
    "    caracteristicas = transforma_imagen(imagen, sizeVentana, tamanoMax)\n",
    "    X.append(caracteristicas)\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.hstack((np.ones(len(dogTrain)), np.zeros(len(catTrain)))).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcef508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perros Test:  10%|\u001b[38;2;255;136;187m███████                                                               \u001b[0m| 2/20 [00:02<00:21,  1.17s/it]\u001b[0m"
     ]
    }
   ],
   "source": [
    "Xtest = []\n",
    "for i in tqdm(range(len(dogTest)), desc = \"Perros Test\", colour = '#FF88BB'):\n",
    "    imagen = cv2.imread(f'{rutaDogsTest}/{dogTest[i]}',0)\n",
    "    caracteristicas = transforma_imagen(imagen, sizeVentana, tamanoMax)\n",
    "    Xtest.append(caracteristicas)\n",
    "\n",
    "for i in tqdm(range(len(catTest)), desc = \"Gatos Test\", colour = '#88FFE0'):\n",
    "    imagen = cv2.imread(f'{rutaCatsTest}/{catTest[i]}',0)\n",
    "    caracteristicas = transforma_imagen(imagen, sizeVentana, tamanoMax)\n",
    "    Xtest.append(caracteristicas)\n",
    "    \n",
    "Xtest = np.array(Xtest)\n",
    "ytest = np.hstack((np.ones(len(dogTest)), np.zeros(len(catTest)))).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f9985a",
   "metadata": {},
   "source": [
    "Particionamos el conjunto de datos para obtener el conjunto de validación (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size = 0.15, random_state = 42)\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc938ca",
   "metadata": {},
   "source": [
    "Importamos las liberías para usar redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e23c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, LSTM, TimeDistributed, GRU, SimpleRNN\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "print(tf.config.list_physical_devices())\n",
    "print(\"Número de GPUs disponibles: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0241fc",
   "metadata": {},
   "source": [
    "Creamos un modelo simple porque no nos vamos a centrar en redes neuronales, más adelante utilizaremos SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_shape = (16384,)),\n",
    "    Dropout(0.28),\n",
    "    Dense(32),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer = keras.optimizers.Adamax(), loss = keras.losses.binary_crossentropy, metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "historico = model.fit(\n",
    "    Xtrain, \n",
    "    ytrain, \n",
    "    batch_size = 1000, \n",
    "    epochs = 64,\n",
    "    validation_data= (Xval, yval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfaa0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "historial = historico.history\n",
    "plt.title('Gráfica de coste')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Coste')\n",
    "plt.plot(historial['loss'])\n",
    "plt.plot(historial['val_loss'])\n",
    "plt.legend([\"Train\", \"Val\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Gráfica de accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(historial['acc'])\n",
    "plt.plot(historial['val_acc'])\n",
    "plt.legend([\"Train\", \"Val\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaddcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = model.predict(Xtest)\n",
    "aciertos = np.sum(np.round(prediccion) == ytest)\n",
    "print(f'Precisión en test: {aciertos/ytest.shape[0]*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f61b18d",
   "metadata": {},
   "source": [
    "## SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db18b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las SVMs\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creamos un clasificador SVM usando svm.SVC con kernel='linear', C = 1.0\n",
    "clf = make_pipeline(StandardScaler(),  svm.SVC(kernel = 'linear', C = 1))\n",
    "#clf = make_pipeline(StandardScaler(),  svm.SVC(C = 2))\n",
    "\n",
    "# Entrenamos el modelo\n",
    "clf.fit(X, y.ravel())\n",
    "# Obtenemos la precisión\n",
    "accTrain = clf.score(X, y)\n",
    "print(\"Precisión en train: {}%\".format(accTrain*100))\n",
    "\n",
    "print(f\"Precisión en test: {clf.score(Xtest, ytest)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3094f5eb",
   "metadata": {},
   "source": [
    "#### Hemos obtenido un 90% de precisión en Test con ambos modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38ml] *",
   "language": "python",
   "name": "conda-env-py38ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
